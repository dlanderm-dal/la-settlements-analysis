David Landerman---
title: "la_reverse_engineering"
output: html_document
date: "2025-10-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#option_command_i

#Loading Libaries
```{r}
library(tidyverse)
library(rio)
library(lubridate)
library(janitor)
```

#control-click-hold option, copy path

#'/Users/davidlanderman/UMD Drive/Github/jour772/project/reverse engineering/la-settlements-analysis/input/payouts.xlsx'

```{r}
payouts<-rio::import('/Users/davidlanderman/UMD Drive/Github/reverse engineering/la-settlements-analysis/input/payouts.xlsx', skip=1, header=TRUE)
#skip/delete the wonky top row, make the second row into headers
  payouts<-payouts %>% 
    #the bottom two rows are a space and then a grand total, this will screw up the data. Slice_head means filtering by that number of rows, I tried to use slice_tail(n=2) but it gave me JUST the bottom two rows, so I did total rows minus 2 and slice_head.
    slice_head(n=18701) %>% 
    clean_names()
```
AI USE DISCLOSURE I (for import)
Googled "is there a way to import a csv into r and delete the top row and use row 2 as the header"
The first link was substack, read it, not helpful but the top result was google's ai which said this
"Yes, it is possible to import a CSV file into R, skip the first row, and use the second row as the header. This can be achieved using the read.csv() function from base R or the read_csv() function from the readr package.
Using read.csv() (Base R):
Code

data <- read.csv("your_file.csv", skip = 1, header = TRUE)"
*END AI DISCLOSURE I*



Paragraph 2 Recreation:
Text: "Beyond the mammoth cases, a pileup of other large payouts has padded the tab, a Times analysis of city payouts found. While the total number of payouts has dipped over time{FINDING 1}, the average amount has increased{FINDING 2}. Last budget year, the city paid out 30 settlements of $1 million or more{FINDING 3} — five times as many as a decade before{FINDING 4}."

Method:
Pivot table of number of cases each year with a separate column for average amount of payout, and total just in case I need it. Also need to figure out how to put a separate count column that somehow also has a filter inside it for over 1 million. Because this table is larger, I will save it as a new dataframe.

Generating the relevant analysis:
```{r}
payout_trends_summary<-payouts %>% 
  group_by(fiscal_year) %>% 
  summarize(
    number_of_cases_in_each_year=n(),
    total_for_year=sum(amount,na.rm=TRUE),
    average_payout=mean(amount,na.rm=TRUE),
    #then filter the rows in the source table to rows with the amount column has a value over 1 million then count how many rows each fiscal_year value has that meet that condition for a column in the pivot table *SEE AI DISCLOSURE 2.1, for troubleshooting of the following line* 
    number_of_cases_over_one_million=sum(amount >= 1000000,na.rm=TRUE)
  )

```

Pulling the findings:
FINDING 1:"the total number of payouts has dipped over time"
```{r}
payout_trends_summary %>% 
  #SEE AI DISCLOSURE 2.2 for troubleshooting of the following line only (if I am using AI to troubleshoot too much please let me know, for the record I am attempting, then googling, then if I cant find/understand what I've found I go to CLAUDE) 
  mutate(pct_change=((number_of_cases_in_each_year-first(number_of_cases_in_each_year))/first(number_of_cases_in_each_year))*100) %>% 
   mutate(difference_from_baseline=(number_of_cases_in_each_year-first(number_of_cases_in_each_year)))%>%
  select(fiscal_year,number_of_cases_in_each_year,difference_from_baseline,pct_change)
#DL to RW question: trends difference from article suggest missing data cleaning step, search "DATA CLEANING INVESTIGATION" in this code for what I'd like your thoughts on
  
 
```

FINDING 2: "the average amount has increased"
```{r}
payout_trends_summary %>% 
   mutate(pct_change=((average_payout-first(average_payout))/first(average_payout))*100) %>% 
   mutate(difference_from_baseline=(average_payout-first(average_payout)))%>%
  select(fiscal_year,average_payout,difference_from_baseline,pct_change)
```

FINDING 3:"Last budget year, the city paid out 30 settlements of $1 million or more"
```{r}
payout_trends_summary %>% 
filter(fiscal_year==2017) %>% 
select(fiscal_year,number_of_cases_over_one_million)
```
FINDING 4:"five times as many as a decade before" 2017 had 5x as many payments of over 1 million dollars compared to 2007
```{r}
payout_trends_summary %>% 
filter(fiscal_year==2007|fiscal_year==2017) %>%
  mutate(decade_change_multiplier=number_of_cases_over_one_million/first(number_of_cases_over_one_million)) %>% 
select(fiscal_year,number_of_cases_over_one_million,decade_change_multiplier)
```


PARAGRAPH 2 RECREATION: AI DISCLOSURE

AI USE DISCLOSURE 2.1: 
I tried the code in the prompt and got an error related to trying to filter inside an n(). I found it hard to figure out exactly what I was looking for online so I asked Claude a very specific prompt so it wouldn't over-explain/make this too easy on me.
David: In R with the following libraries loaded (tidyverse, rio, lubridate, janitor) and the following code run: 

#```{r}
payouts %>% 
  group_by(fiscal_year) %>% 
  summarize(
    number_of_cases_in_each_year=n(),
    total_for_year=sum(amount,na.rm=TRUE),
    average_payout=mean(amount,na.rm=TRUE),
    #then filter the rows in the source table to rows with the amount column has a value over 1 million then count how many rows each fiscal_year value has that meet that condition for a column in the pivot table
    number_of_cases_over_one_million=n(filter(amount>=1000000))
  )
'''

Generating the following error:
Error in summarize(): ℹ In argument: number_of_cases_over_one_million = n(filter(amount >= 1e+06)). ℹ In group 1: fiscal_year = 2006. Caused by error in n(): ! unused argument (filter(amount >= 1e+06)) Run rlang::last_trace() to see where the error occurred.
Considering the comment that begins with "#then filter the rows in the source table" explaining the intent of the following line, QUESTION: What went wrong with how I wrote the code in that line?

RESPONSE GUIDELINE: Be as succinct as possible, do not over-explain. Give me the corrected LINE of code (not the whole chunk) and one sentence about why what I did was wrong and THAT IS IT!

CLAUDE: r
number_of_cases_over_one_million=sum(amount >= 1000000, na.rm=TRUE)

You tried to pass filter() as an argument to n(), but n() counts all rows in the group without arguments—use sum() with a logical condition instead to count rows meeting your criteria.
DAVID: wouldn't sum give me the sum of all the amounts in those rows of over 1000000, I want to know how many rows exist with amounts of 1 million. Hypothetically if there are 10 rows in a given fiscal year with each having exactly 1 million for amount then I want this code to generate the number 10 for that row in the pivot table not 10 million. Will what you gave me generate 10 or 10 million for the value in the pivot table row?

CLAUDE: It will generate 10, not 10 million.
When you use sum() on a logical condition like amount >= 1000000, R converts TRUE to 1 and FALSE to 0, then sums those 1s and 0s, giving you the count of TRUE values (i.e., the number of rows meeting the condition).

DAVID: Ok so conversely if I wanted to generate 10 million from that example how would I do that? If I wanted the sum of the amounts for all the rows over 1 million?

CLAUDE: r
sum_of_cases_over_one_million=sum(amount[amount >= 1000000], na.rm=TRUE)
Use bracket subsetting amount[amount >= 1000000] to filter the amounts first, then sum() adds up those filtered values.

DAVID: are you sure its brackets not parenthesis? If so why?

CLAUDE: Yes, brackets [ ] not parentheses ( ).
Brackets are R's subsetting operator that extracts elements from a vector based on a logical condition, while parentheses are for function calls—amount[amount >= 1000000] means "give me the values from amount where the condition is TRUE."
*END AI DISCLOSURE*

AI DISCLOSURE 2.2
DAVID:For another purpose, subtracting  each value in the column number_of_cases_in_each_year by the first value (which corresponds to fiscal year 2016) I tried this code and the column it returned had values that were all NA. What did I do wrong? be succinct
payout_trends_summary %>% 
  mutate(difference_from_baseline=number_of_cases_in_each_year-number_of_cases_in_each_year[fiscal_year=2006]) %>% 
  select(fiscal_year,number_of_cases_in_each_year,difference_from_baseline)

CLAUDE: r
difference_from_baseline=number_of_cases_in_each_year-number_of_cases_in_each_year[fiscal_year==2006]
You used = (assignment) instead of == (comparison) inside the brackets, so the condition failed and returned NA.

DAVID: And if I wanted to generalize the first year (i.e. not use 2006)

CLAUDE:r
difference_from_baseline=number_of_cases_in_each_year-first(number_of_cases_in_each_year)
Use first() to grab the first value in the column without hardcoding the year.
*END AI DISCLOSURE 2.2*

DATA CLEANING INVESTIGATION: I noticed the paragraph said "cases dipped over time" but I didn't see that in the data so I looked to make sure I didn't miss a data cleaning step. I went to amounts and sorted by amount to see if I had any NA rows. However I found some large negative values. I first wondered if these were mislabled and I should apply some kind of absolute value filter (all negatives multiply by -1), but then I looked up the case numbers and saw there were duplicates, so these were amounts returned to the city. Then I saw some cases had 3 lines like one that had a 15million, a negative 15million, then another positive 15million. Thought that might make the data wonky, counting one case as three. Think I may have to filter out one negative payment and its corresponding positive payment if they cancel each other out. Better yet, a net amount on each case number. I wonder how I could do that without accidentally combinign casenumber with values of NA from different years.





